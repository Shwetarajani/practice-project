{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cf44d49",
   "metadata": {},
   "source": [
    "# Flight Price Prediction\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "beed78c6",
   "metadata": {},
   "source": [
    "Problem Statement:\n",
    "Flight ticket prices can be something hard to guess, today we might see a price, check out the price of the same flight tomorrow, it will be a different story. We might have often heard travellers saying that flight ticket prices are so unpredictable. Here you will be provided with prices of flight tickets for various airlines between the months of March and June of 2019 and between various cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bbbd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4597965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dataset\n",
    "# Reading excel file in a dataframe\n",
    "df = pd.read_excel('Data_Train.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8522da52",
   "metadata": {},
   "source": [
    "The train dataset contains the details of the prices of flight tickets for various airlines between the months of March and June of 2019 and between various cities. The dataset contains both numerical and categorical data. Here Price is the target variable and as it has continuous data, its a Regression Problem Statement where we use Regression algorithms to predict the prices of the flight tickets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca52a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking top 5 records\n",
    "#Displaying first five rows of the dataset.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defd8b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploratory Data Analysis(EDA)\n",
    "# Checking the dimensions of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22180117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get good overview of the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "80d1f435",
   "metadata": {},
   "source": [
    "This gives the information about the dataset which includes indexing type, column type, not-null values and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e32be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dtypes of dataset\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59a6e195",
   "metadata": {},
   "source": [
    "We can see that the train dataset has only object and int64 datatypes."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d129c21f",
   "metadata": {},
   "source": [
    "Feature Engineering\n",
    "Working on all the columns and converting them to numeric\n",
    "\n",
    "The columns Date_of_Journey,Arrival_Time and Dep_Time has datetime datatype but its reflecting as object. So lets convert this datatype into timestamp to use it properly for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4630328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Date and time columns from object type to Datetime type\n",
    "df['Date_of_Journey'] = pd.to_datetime(df['Date_of_Journey'])\n",
    "df['Dep_Time'] = pd.to_datetime(df['Dep_Time'])\n",
    "df['Arrival_Time']=pd.to_datetime(df['Arrival_Time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f02bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rechecking the datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dbc4d4ac",
   "metadata": {},
   "source": [
    "We have converted object datatype into datetime datatype.\n",
    "\n",
    "Now splitting Date_of_journey into Month and Day, and as the dataset contains only 2019 year data so no need to take year column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1ce4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Day from Date_of_journey column\n",
    "df['Journey_Day'] = pd.to_datetime(df.Date_of_Journey,format=\"%d/%m/%Y\").dt.day\n",
    "\n",
    "# Extracting Month from Date_of_journey column\n",
    "df['Journey_Month'] = pd.to_datetime(df.Date_of_Journey, format=\"%d/%m/%Y\").dt.month"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57a9c06e",
   "metadata": {},
   "source": [
    "So we have splitted the column Date_of_Journey into integer datatype , now we can drop this column as it is of no use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6774528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Date_of_journey column\n",
    "df.drop(\"Date_of_Journey\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ee27c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration\n",
    "\n",
    "df['Duration']=df['Duration'].str.replace('h','*60').str.replace(' ','+').str.replace('m','*1').apply(eval)\n",
    "\n",
    "#now lets convert this column into a numeric\n",
    "\n",
    "df['Duration']=pd.to_numeric(df['Duration'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45891da6",
   "metadata": {},
   "source": [
    "Extracting hours and mins from Dep_Time column and dropping Dep_Time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c26d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Hours from Dep_Time column\n",
    "df['Dep_Hour']=pd.to_datetime(df['Dep_Time']).dt.hour\n",
    "\n",
    "# Extracting Minutes from Dep_Time column\n",
    "df['Dep_Min']=pd.to_datetime(df['Dep_Time']).dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aa3307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Dep_Time column\n",
    "df.drop(\"Dep_Time\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2afeb917",
   "metadata": {},
   "source": [
    "Similarly extracting hours and mins from Arrival_Time column and dropping that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bafda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Arrival_Hour from Arrival_Time column\n",
    "df['Arrival_Hour']=pd.to_datetime(df['Arrival_Time']).dt.hour\n",
    "\n",
    "# Extracting Arrival_Min from Arrival_Time column\n",
    "df['Arrival_Min']=pd.to_datetime(df['Arrival_Time']).dt.minute\n",
    "\n",
    "# Dropping Arruval_Time column\n",
    "df.drop(\"Arrival_Time\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4146863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check dataframe now\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30770c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dimension of dataframe now\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "28b886e2",
   "metadata": {},
   "source": [
    "Lets check value counts in each column to find if there are any unexpected or corrupted entries in the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414916e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the value counts of each column\n",
    "for i in df.columns:\n",
    "    print(df[i].value_counts())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3732c63",
   "metadata": {},
   "source": [
    "here are the list of unique values present in the columns.\n",
    "\n",
    "From the above list of unique values,we can observe some repeated categories in some columns. Lets replace them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fca63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing \"Jet Airwaus Business\" as \"Jet Airways\" in the column Airline\n",
    "df[\"Airline\"]=df[\"Airline\"].replace(\"Jet Airways Business\",\"Jet Airways\")\n",
    "\n",
    "# Replacing \"Multiple carriers Premium economy\" as \"Multiple carriers\" in Airline column\n",
    "df['Airline']=df[\"Airline\"].replace(\"Multiple carriers Premium economy\",\"Multiple carriers\")\n",
    "\n",
    "# Replacing \"Vistara Premium economy\" as \"Vistara\" in Airline column\n",
    "df[\"Airline\"] = df[\"Airline\"].replace(\"Vistara Premium economy\",\"Vistara\")\n",
    "\n",
    "# Replacing \"New Delhi\" as \"Delhi\" in Destination column\n",
    "df[\"Destination\"] = df[\"Destination\"].replace(\"New Delhi\",\"Delhi\")\n",
    "\n",
    "# In the column \"Additional Info\", \"No Info\" and \"No info\" are same so replacing it by \"No Info\n",
    "df['Additional_Info'] = df['Additional_Info'].replace(\"No info\", \"No Info\")\n",
    "\n",
    "# Replacing \"1 Long Layover\" and \"2 Long layover\" as \"Long layover\" in the column Additional Info\n",
    "df['Additional_Info']=df['Additional_Info'].replace([\"1 Long layover\",\"2 Long layover\"],\"Long layover\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88daa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rechecking the unique values in the above columns\n",
    "val_count = [\"Airline\",\"Destination\",\"Additional_Info\"]\n",
    "\n",
    "for i in val_count:\n",
    "    print(df[i].value_counts())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81e8d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking number of unique values in each column\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61436e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for null values in the dataframe\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "82ab452f",
   "metadata": {},
   "source": [
    "We can observe null values in Route and Total_Stops column. As both the columns have categorical data, we can fill them using mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8535fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling Null values using imputation techniques.\n",
    "# Checking the mode of Categorical columns \"Route\" and \"Total_Stops\"\n",
    "print(\"The mode of Route is:\",df[\"Route\"].mode())\n",
    "print(\"The mode of Total_Stops is:\",df[\"Total_Stops\"].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a04bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling the missing values in \"Route\" withs its mode\n",
    "df['Route'] = df['Route'].fillna(df['Route'].mode()[0])\n",
    "\n",
    "# Filling the mising values in \"Total_Stops\" by its mode\n",
    "df['Total_Stops']=df['Total_Stops'].fillna(df['Total_Stops'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df88c025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values now\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effed72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lest check missing values using heatmap\n",
    "sns.heatmap(df.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b453bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for columns in the dataset\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add929fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the uniqueness of target column\n",
    "df[\"Price\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cfd95f",
   "metadata": {},
   "outputs": [],
   "source": [
    " Checking the list of counts in the target column.\n",
    "df[\"Price\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8f1878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether the dataset contains any space\n",
    "df.loc[df['Price']==\" \"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "902b0351",
   "metadata": {},
   "source": [
    "There is no empty space in any of the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfa0e9c",
   "metadata": {},
   "source": [
    "Description of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0c3954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c628c466",
   "metadata": {},
   "source": [
    "This gives the statistical information of the dataset. The summary looks perfect since there is no negative/invali values present. It gives the summary of numerical data.\\ From the above description we can observe the following things.\n",
    "\n",
    "The counts of all columns are same which means ther are no missing values present int he dataset.\n",
    "The mean value is greater than the median(50%) in the columns Price,Journey_Day,Duration and Dep_Hour so we can say they are skewed to right.\n",
    "The median(50%) is bit greater than mean in Dep_Min,Arrival_Hour and Arrival_Min which means they are skewed to left.\n",
    "From the description we can say the minimum price of the flight tickets is Rs.1759 and maximum price is Rs.79512 and the mean is 9087.\n",
    "Also there is a huge difference in maximum and 75% percentile in the columns Price, Arrival_Min which leads to outlies in thoe columns.\n",
    "The std of target variable is high which means it has high rate of dispersion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ae0c0f",
   "metadata": {},
   "source": [
    "Description Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548a4557",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,12))\n",
    "sns.heatmap(round(df.describe()[1:].transpose(),2),linewidth = 2, annot = True, fmt = '.2f')\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.title(\"Variable Summary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4287209",
   "metadata": {},
   "source": [
    "Lets separate numerical and categorical column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacc66ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking categorical columns\n",
    "categorical_col = []\n",
    "for i in df.dtypes.index:\n",
    "    if df.dtypes[i]=='object':\n",
    "        categorical_col.append(i) \n",
    "print(categorical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c0cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking numerical column\n",
    "numerical_col = []\n",
    "for i in df.dtypes.index:\n",
    "    if df.dtypes[i]!='object':\n",
    "        numerical_col.append(i)\n",
    "print(numerical_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad34b87",
   "metadata": {},
   "source": [
    "Data Visualization\n",
    "\n",
    "\n",
    "Univariate Analysis\n",
    "\n",
    "\n",
    "Plotting Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa28c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the various Airlines present in the dataset\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(df[\"Airline\"])\n",
    "plt.title(\"Count of flights in different Airlines\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "06677f12",
   "metadata": {},
   "source": [
    "Jet Airways flights has high counts whereas Trujet and GoAir has the least counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab8cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the various Source from which place the service begins\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(df[\"Source\"])\n",
    "plt.title(\"Count of different Airline Sources\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35a53706",
   "metadata": {},
   "source": [
    "The majority of Airline source is from Delhi while the least is from Chennai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71d5636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the destination from which place the service ends\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(df[\"Destination\"])\n",
    "plt.title(\"Count of destination\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "310978d1",
   "metadata": {},
   "source": [
    "The Cochin destination has highest counts. Most of the flights services ends in Cochin destination.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba69630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Total Stops between the source and the destination\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(df[\"Total_Stops\"])\n",
    "plt.title(\"Count of Total Stops between the source and the destination\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ab04a46",
   "metadata": {},
   "source": [
    "Majority of flights has 1 stop between the source and destination, followed by non stop. No flights have 4 stops between the source and destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b039fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Additional Information about the flight\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(df[\"Additional_Info\"])\n",
    "plt.title(\"Count of Additional Information about the flight\")\n",
    "plt.xticks(rotation=75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3466fd7f",
   "metadata": {},
   "source": [
    "here is no much information about the flights that we can see in the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44768a6c",
   "metadata": {},
   "source": [
    "Distribution of skewness\n",
    "\n",
    "Plotting numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9085cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking numerical columns\n",
    "plt.figure(figsize=(15,15))\n",
    "plotnumber=1\n",
    "for col in numerical_col:\n",
    "    if plotnumber<=8:\n",
    "        ax = plt.subplot(3,3,plotnumber)\n",
    "        sns.distplot(df[col],color='indigo')\n",
    "        plt.xlabel(col,fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "74c65356",
   "metadata": {},
   "source": [
    "From the distribution plot we can observe that the data i not normally distributed in some columns and some columns are almost normal but have no proper bell shape curve. The Journey_Month, Duration and Price columns are skewed to right as mean is more than the median."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ae42a6",
   "metadata": {},
   "source": [
    "Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f577fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check which Airline is expensive based on Price of tickets\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.barplot(df['Airline'],df[\"Price\"],data=df)\n",
    "plt.title(\"Checking which Airline is expensive based on ticket price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df2f0403",
   "metadata": {},
   "source": [
    "The barplot shows that the Jet Airways is most expensive Airline followed by Multiple carriers and Air India.\n",
    "The Trujet and Spicejet have low ticket prices compared to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82fefed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check how prices changes in each destination \n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(df[\"Destination\"],df[\"Price\"],data=df,palette=\"husl\" )\n",
    "plt.title(\"Checking deastination based on ticket price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d01a3c0",
   "metadata": {},
   "source": [
    "The ticket price is high in Cochin destination followed by Bangalore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabcf1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the price vs total stops\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(df[\"Total_Stops\"],df[\"Price\"],data=df,palette=\"ch:.28\")\n",
    "plt.title(\"Checking how price changes based on Stops\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f219b79",
   "metadata": {},
   "source": [
    "We can see flights with 4 stops have highest price followed by flights having 3 stops and the flights which have no stops is having very less ticket price compared to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb77d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's compare Additional_Info and Price of the flights\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(df[\"Additional_Info\"],df[\"Price\"],data=df)\n",
    "plt.title(\"Checking how the prices changes with Additional_Info\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6dc86f14",
   "metadata": {},
   "source": [
    "This plot shows that the Business class flights are more expensive compared to others and the flights having the class No check-in baggage included has very least ticket price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8681b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2,figsize=(18,15))\n",
    "\n",
    "# Checking relation between Journey_Day and Price\n",
    "sns.boxenplot(x='Journey_Day',y='Price',ax = axes[0,0],data=df)\n",
    "\n",
    "# Checking relation between Journey_Mionth and Price\n",
    "sns.barplot(x='Journey_Month',y='Price',ax = axes[0,1],data=df,color='c')\n",
    "\n",
    "# Checking relation between Dep_Min and Price\n",
    "sns.boxplot(x='Dep_Min',y='Price',ax=axes[1,0],data=df)\n",
    "\n",
    "# Checking relation between Dep_Hour and Price\n",
    "sns.barplot(x='Dep_Hour',y='Price',ax=axes[1,1],data=df,palette=\"bright\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20b5619e",
   "metadata": {},
   "source": [
    "From the above plots we can observe the following\n",
    "\n",
    "While comparing Journey_Day and Price we can see the price of ticket is high in Day 3 apart from this there is no much impact of day on ticket price.\n",
    "While comparing Journey_Month and Price we can state that the flights travelling in January month are more expensive than others and the flights traveeling in April month have very cheap ticket prices.\n",
    "There is no significance relation between Dep_Min and Price of the tickets.\n",
    "In the fourth graph also we can say that there is no much impact of Dep_Hour on Proice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0f4d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how the price pays role in Airline on the basis of destination\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.stripplot(x=df['Airline'],y=df['Price'],hue=df[\"Destination\"])\n",
    "plt.title(\"Comparing Airline and Price on the basis of Destination\")\n",
    "plt.xticks(rotation=75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "165f437a",
   "metadata": {},
   "source": [
    "Here we can conclude that the JetAirways flights taht are destined to Delhi are having more expensive ticket prices compared to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ebbb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking relation between Arrival_Hour and Price\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title(\"Checking relation between Arrival_Hour and Price\")\n",
    "sns.stripplot(x='Arrival_Hour',y='Price',data=df, palette=\"ch:.28\")\n",
    "plt.xticks(rotation=75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59461563",
   "metadata": {},
   "source": [
    "And we can see there is no relation of Arrival_time with the Price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cf4e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how the price pays role in Source on the basis of Total_Stops\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.stripplot(x=df['Source'],y=df['Price'],hue=df[\"Total_Stops\"])\n",
    "plt.title(\"Comparing Source and Price on the basis of Total_Stops\")\n",
    "plt.xticks(rotation=75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9592a740",
   "metadata": {},
   "source": [
    "As we can say that the flights in the Bangalore source which have only one stop between source and detination are very expensive while Chennai with no stops have very cheap prices compared to other source flights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5891e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,hue=\"Price\",palette='husl')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "341e2be9",
   "metadata": {},
   "source": [
    "This pairplot gives the pairwise relation betweeen the columns which is plotted on the basis of target variable \"Price\". Here we can observe the relation between the features and the label.\n",
    "Here we can observe the correlation between the features and on the diagonal we can notice the distribution plot which shows whether the columns has skewness or not.\n",
    "We can also see the linear relation between the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e371ca7e",
   "metadata": {},
   "source": [
    "Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a12e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying the outliers using boxplot\n",
    "\n",
    "plt.figure(figsize=(15,15),facecolor=\"white\")\n",
    "plotnumber=1\n",
    "for col in numerical_col:\n",
    "    if plotnumber<=8:\n",
    "        ax = plt.subplot(3,3,plotnumber)\n",
    "        sns.boxplot(df[col],color=\"darkorange\")\n",
    "        plt.xlabel(col,fontsize=15)\n",
    "    plotnumber+=1\n",
    "plt.tight_layout()  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b05b6ca",
   "metadata": {},
   "source": [
    "The outliers are present in the columns \"Duration\",\"Journey_Month\" and the target variable \"Price\".\n",
    "Since \"Price\" is the target column so no need to remove outliers from this column.\n",
    "We need to remove the outliers from the other two columns using zscore or IQR methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31d573",
   "metadata": {},
   "outputs": [],
   "source": [
    "Removing Outliers\n",
    "\n",
    "\n",
    "Zscore method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a96c2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "# Features containing outliers\n",
    "features = df[[\"Duration\",\"Journey_Month\"]]\n",
    "z = np.abs(zscore(features))\n",
    "z"
   ]
  },
  {
   "cell_type": "raw",
   "id": "902fa3ac",
   "metadata": {},
   "source": [
    "The outliers are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc82e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new dataframe\n",
    "new_df = df[(z<3).all(axis=1)]\n",
    "new_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4143bf2a",
   "metadata": {},
   "source": [
    "This is the new dataframe after removing outliers. Here we have removed the outliers whose zscore is less than 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8076a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the dimensions of both dataframes.\n",
    "print(df.shape)\n",
    "print(new_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5291612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking data loss\n",
    "loss = (10683-10617)/10683*100\n",
    "loss"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3afd22a5",
   "metadata": {},
   "source": [
    "Here we are losing very less data. Lets try using IQR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53feb4e9",
   "metadata": {},
   "source": [
    "IQR(InterQuantileRange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f7aa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st quantile\n",
    "Q1 = features.quantile(0.25)\n",
    "\n",
    "#3rd quantile\n",
    "Q3 = features.quantile(0.75)\n",
    "\n",
    "IQR = Q3-Q1\n",
    "\n",
    "df1 = df[~((df<(Q1-1.5*IQR))|(df>(Q3+1.5*IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68b15f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc7b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking data loss using IQR\n",
    "loss = (10683-9657)/10683*100\n",
    "loss"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05bfd0ac",
   "metadata": {},
   "source": [
    "Using IQR method we are losing 9.6% data. Lets consider Zscore method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59670ef8",
   "metadata": {},
   "source": [
    "Checking Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afa52d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking skewness \n",
    "new_df.skew()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ba88091",
   "metadata": {},
   "source": [
    "Outcome of the skewness:\n",
    "\n",
    "Skewness threshold is taken as +/-0.65.\n",
    "We can find the skewnwss present in Price, Duration and Journey_Month columns.\n",
    "As Price is the target column no need to remove skewness from that column but will remove skewness from the other two columns."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3839fc6e",
   "metadata": {},
   "source": [
    "Removing Skewness using log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b9cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['Duration'] = np.log1p(new_df['Duration'])\n",
    "new_df['Journey_Month'] = np.log1p(new_df['Journey_Month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae0b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking skewness again\n",
    "new_df.skew()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1fa5ff16",
   "metadata": {},
   "source": [
    "We can observe the skewness has been removed from Duration and Journey_Month columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fdd491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how the data has been distributed after removing skewness.\n",
    "skew = [\"Duration\",\"Journey_Month\"]\n",
    "plt.figure(figsize=(15,15),facecolor=\"white\")\n",
    "plotnumber=1\n",
    "for column in new_df[skew]:\n",
    "    if plotnumber<=2:\n",
    "        ax = plt.subplot(2,2,plotnumber)\n",
    "        sns.distplot(df[column],color='g',kde_kws={\"shade\": True},hist=False)\n",
    "        plt.xlabel(column,fontsize=20)\n",
    "    plotnumber+=1\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87366ea3",
   "metadata": {},
   "source": [
    "The data looks almost normal and skewness is also removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e64601",
   "metadata": {},
   "source": [
    "Label Encoding Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47251736",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2b29a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lbl = LabelEncoder()\n",
    "new_df[categorical_col]=new_df[categorical_col].apply(lbl.fit_transform)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2825e4cf",
   "metadata": {},
   "source": [
    "We have converted the categorical columns into numerical columns using label encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b8ac5a",
   "metadata": {},
   "source": [
    "Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1ce3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the correlation between features and label\n",
    "cor = new_df.corr()\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad57ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the correlation matrix by plotting heatmap.\n",
    "plt.figure(figsize=(20,15))\n",
    "sns.heatmap(new_df.corr(),linewidths=.1,fmt=\".1g\",linecolor=\"black\",annot=True,cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39fe8937",
   "metadata": {},
   "source": [
    "This heatmap shows the correaltion matrix by visualizing the data. We can observe the relation between one feature to other.\n",
    "\n",
    "This heatmap contain both positive and negative correlation.\n",
    "The feature Duration is highly positively correlated with the target variable \"Price\".\n",
    "The feature Total_Stops is highly Negatively correlated with the label.\n",
    "The features Duration, Total_Stops and Destination are highly negatively correlated with each other.This may lead to multicollinearity problem, we will check vif values to avoid this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c15c37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor[\"Price\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f018a7e",
   "metadata": {},
   "source": [
    "We can see the positive and negative correlation of target and features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff07a9e",
   "metadata": {},
   "source": [
    "Visualizing the correlation between features and label using bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e00614",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22,7))\n",
    "new_df.corr()[\"Price\"].sort_values(ascending=False).drop([\"Price\"]).plot(kind=\"bar\",color=\"purple\")\n",
    "plt.xlabel('Features',fontsize=20)\n",
    "plt.ylabel('Target',fontsize=20)\n",
    "plt.title('Correlation between label and features using barplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b46a01a",
   "metadata": {},
   "source": [
    "The features Journey_Month, Source, Arrival_Hour,Dep_Hour and Airline have very less correlation with the label so we can drop thee columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f60a7b",
   "metadata": {},
   "source": [
    "Separating the features and label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83dd030",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = new_df.drop(\"Price\",axis=1)\n",
    "y = new_df[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfec4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fe0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bd8d98",
   "metadata": {},
   "source": [
    "Feature Scaling using Standard Scalarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5844c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x = pd.DataFrame(scaler.fit_transform(x),columns=x.columns)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b00b5644",
   "metadata": {},
   "source": [
    "We have scaled the data using Standard Scalarization method to overcome the problem of biasness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e96ede",
   "metadata": {},
   "source": [
    "Checking VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9692c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding variance inflation factor\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Values\"] = [variance_inflation_factor(x.values,i) for i in range(len(x.columns))]\n",
    "vif['Features'] = x.columns\n",
    "vif"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5df340e7",
   "metadata": {},
   "source": [
    "As we can notice the vif values is less than 10 in all the columns,there is no multicollinearity exists. WE can move ahead for model building."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60c1e22",
   "metadata": {},
   "source": [
    "Modeling\n",
    "\n",
    "Finding the best random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea07ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as TTS\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9269f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "maxAccu = 0\n",
    "maxRS = 0\n",
    "for i in range(1,200):\n",
    "    x_train,x_test,y_train,y_test = TTS(x,y,test_size=0.30,random_state=i)\n",
    "    mod = RandomForestRegressor()\n",
    "    mod.fit(x_train,y_train)\n",
    "    pred = mod.predict(x_test)\n",
    "    acc = r2_score(y_test,pred)\n",
    "    if acc>maxAccu:\n",
    "        maxAccu = acc\n",
    "        maxRs = i\n",
    "print(\"Maximum r2_score is \",maxAccu,\"at random_state\",maxRS)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dfead5",
   "metadata": {},
   "source": [
    "Creating new train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = TTS(x,y,test_size=0.30,random_state=maxRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c057c85",
   "metadata": {},
   "source": [
    "Regression Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9907798f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor,BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a67aee",
   "metadata": {},
   "source": [
    "Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee78560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking R2 score for RandomForestRegressor\n",
    "RFR = RandomForestRegressor()\n",
    "RFR.fit(x_train,y_train)\n",
    "predRFR = RFR.predict(x_test)\n",
    "print(\"R2_score:\",r2_score(y_test,predRFR))\n",
    "print(\"MAE:\",metrics.mean_absolute_error(y_test,predRFR))\n",
    "print(\"MSE:\",metrics.mean_squared_error(y_test,predRFR))\n",
    "print(\"RSME:\",np.sqrt(metrics.mean_squared_error(y_test,predRFR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2276e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the predicted values\n",
    "sns.regplot(y_test,predRFR,color='darkorange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88d21cbb",
   "metadata": {},
   "source": [
    "The predicted R2 score using Random Forest Regressor is 88.92%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b49d7e",
   "metadata": {},
   "source": [
    "Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eb8a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking R2 score for DecisionTreeRegressor\n",
    "DTR = DecisionTreeRegressor()\n",
    "DTR.fit(x_train,y_train)\n",
    "predDTR = DTR.predict(x_test)\n",
    "print(\"R2_score:\",r2_score(y_test,predDTR))\n",
    "print(\"MAE:\",metrics.mean_absolute_error(y_test,predDTR))\n",
    "print(\"MSE:\",metrics.mean_squared_error(y_test,predDTR))\n",
    "print(\"RSME:\",np.sqrt(metrics.mean_squared_error(y_test,predDTR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee46d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the predicted values\n",
    "sns.regplot(y_test,predDTR,color='darkorange')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b94d35e3",
   "metadata": {},
   "source": [
    "The predicted R2 score using DecisionTreeRegressor is 77.93%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcd028f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7837010f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6c3bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e62e9a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cf7e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae0fce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c51454b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6a0623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082abeeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bfc6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8013d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35186cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d18a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
